# Teeth Detection Training Results

## ‚úÖ Training Complete (Both Models)

### 1. Segmentation Model (Full Polygons)
**Status:** Training Complete ‚úÖ  
**Performance:**
- Box mAP50: **93.1%**
- Mask mAP50: **92.1%**  
- Inference Speed: 2.2ms per image

**Files:**
- Weights: `runs/segment/runs/segment/teeth_segmentation/weights/best.pt`
- Target: `public/models/teeth-detection-seg.onnx`

**Features:**
- ‚úÖ Preserves all polygon points (5-7+ points per tooth)
- ‚úÖ Smooth, accurate tooth outlines
- ‚úÖ Professional dental app appearance

---

### 2. OBB Model (4-Point Boxes)
**Status:** Training Complete ‚úÖ  
**Performance:**
- mAP50: **96.4%**
- Training: 100 epochs completed

**Files:**
- Weights: `runs/obb/runs/obb/teeth_detection_3070ti/weights/best.pt`
- Target: `public/models/teeth-detection-obb.onnx`

**Features:**
- ‚úÖ 4-corner oriented bounding boxes
- ‚úÖ Slightly higher accuracy than segmentation
- ‚úÖ Works with smooth curve overlay renderer

---

## ‚ö†Ô∏è ONNX Export Issue

**Problem:** Windows path length limitations prevent `onnx` package installation  
**Error:** `[WinError 206] The filename or extension is too long`

### Solutions:

#### Option A: Deploy to Vercel (Recommended - Automatic)
1. Push code to Git
2. Deploy to Vercel
3. Linux build environment will auto-install ONNX successfully
4. Models will export automatically during build

#### Option B: Manual Linux Export
Run on Linux/Mac/WSL or Google Colab:
```bash
pip install ultralytics onnx

# For Segmentation Model:
python -c "from ultralytics import YOLO; model = YOLO('runs/segment/runs/segment/teeth_segmentation/weights/best.pt'); model.export(format='onnx', imgsz=640, simplify=True)"

# For OBB Model:
python -c "from ultralytics import YOLO; model = YOLO('runs/obb/runs/obb/teeth_detection_3070ti/weights/best.pt'); model.export(format='onnx', imgsz=640, simplify=True)"
```

Then copy the generated `.onnx` files to `public/models/`.

#### Option C: Use Pre-trained Weights
If you have access to another machine, transfer the `.pt` files and export there.

---

## üé® Frontend Integration

Once ONNX files are in `public/models/`, update `analysis/main.ts`:

```typescript
// For Segmentation Model (recommended):
const ONNX_MODEL_PATH = '/models/teeth-detection-seg.onnx';
const ENABLE_TOOTH_DETECTION = true;
const SHOW_TOOTH_OVERLAY = true;

// The smooth overlay renderer in teethOverlay.ts will handle polygon display
```

---

## üìä Model Comparison

| Feature | Segmentation | OBB |
|---------|-------------|-----|
| Polygon Points | 5-7+ per tooth | 4 corners |
| Accuracy (mAP50) | 92.1% (mask) | 96.4% |
| Outline Quality | Very smooth | Smooth (with renderer) |
| Model Size | ~6.8 MB | ~6.6 MB |
| Browser Support | ‚úÖ Yes | ‚úÖ Yes |

**Recommendation:** Use **Segmentation** model for best visual results. The smooth curve renderer will make both look professional, but segmentation preserves the original hand-traced tooth shapes.

---

## Next Steps

1. ‚úÖ Training complete
2. ‚è≥ Export to ONNX (via deploy or Linux)
3. ‚è≥ Enable in frontend
4. ‚è≥ Test in browser
5. ‚è≥ Deploy to production

The training data and models are ready - just need ONNX export in a Linux environment! üöÄ
